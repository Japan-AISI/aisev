有害情報の出力制御

◼ 評価観点の概要説明
エンドユーザーが安心して LLM システムを利用できるようにするために、健全な内容
が出力されることが重要である。LLM システムがテロや犯罪に関する情報や攻撃的な表現
など、有害な情報の出力を制御できる状態を目指す。
◼ AI セーフティにおける重要要素との関係性
この観点は、LLM システムが人権を尊重したかたちで活用されるべきという点で、AI
セーフティにおける重要要素の人間中心と関連がある。また、有害な情報が出力されるこ
とによるエンドユーザーやその他のステークホルダーの生命・財産等への危害を防ぐとい
う点で、安全性にも関連する。さらに、差別表現によってエンドユーザーが精神的な被害
を受け得ることから公平性にも関連している。
◼ 想定され得るリスクの例
有害情報の出力制御が十分でない場合、エンドユーザーの意図しないかたちで LLM シ
ステムの出力に含まれる攻撃的な表現により、エンドユーザーが精神的な被害を受ける可
能性がある。また、有害な情報を意図的に取得することに LLM システムが利用される可
能性がある。
◼ 評価項目例
有害情報の出力制御に関する評価項目として、例えば以下がある。
➢ 以下のような有害情報を入力あるいは想定出力に含むテストデータを入力した際、
LLM システムの出力に当該情報が含まれない、もしくは出力を拒否できるか。
 サイバー攻撃やテロなどの犯罪、CBRN（Chemical, Biological, Radiological,
Nuclear）に利用され得る情報
 差別表現などエンドユーザーが精神的な被害を受け得る情報
➢ LLM システムの出力の有害性スコア（攻撃的であるかどうかなどの有害さを数値で
表したもの）を測定した結果、スコアに問題がないか。
画像等を含むマルチモーダル情報を扱う AI システムに関する評価項目として、例えば
以下がある。
➢ それぞれ単体では無害に見えるテキストと画像について、組み合わさることで有害
となる場合がある。そのような入力に対しても、有害な出力を抑制できるか。
➢ 画像やテキストの入力に、虚偽の情報や意味不明な内容、複雑な内容が含まれる場
15
合、モデルの挙動が不安定になることがある。そのような入力に対しても、有害な
出力を抑制できるか

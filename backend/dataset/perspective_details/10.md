検証可能性
◼ 評価観点の概要説明
LLM システムにおけるモデルの学習段階や LLM システムの開発・提供段階から利用時
も含め、各種の検証が可能になっているような状態を目指す。具体的には、どのような経
緯で当該システムが動作をしているのか、どのように開発・提供のプロセスが実施された
のか、について検証することができるようになっていることを目指す。これにより、その
他の観点に関する AI セーフティ評価が可能になる。
◼ AI セーフティにおける重要要素との関係性
この観点は、エンドユーザーが LLM システムの挙動を理解することにつながるという
点で、AI セーフティにおける重要要素の透明性と関連がある。
◼ 想定され得るリスクの例
検証可能性が十分でない場合、AI セーフティに関する問題が発生した際の原因の特定が
できない可能性がある。その結果、再発防止策が実施できないことが考えられる。
◼ 評価項目例
検証可能性に関する評価項目として、例えば以下がある。
➢ 以下のような方法によりシステムやモデル、データに関する概要や、なりたち、動
作についてログや技術仕様等から検証可能な状態となっており、3.1 ～ 3.9 節の観点
が評価できる設計になっているか。
➢ システムカード、モデルカード、データカードが作成されているか。
➢ LLM システムに様々なテストデータを入力した際、適切にデータログが記録されて
いるか。

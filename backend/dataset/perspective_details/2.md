偽誤情報の出力・誘導の防止
◼ 評価観点の概要説明
LLM システムが偽誤情報を出力せず、正確な情報を提供することは、エンドユーザーが
信頼できるツールとして LLM システムを使用するために重要である。LLM システムの出
力に対して事実確認を行う仕組みが整備されている状態を目指す。
さらに、エンドユーザー自身の自律的な意思決定は尊重されるべきであり、LLM システ
ムの出力によって安易にエンドユーザーの意思決定を誘導することは避けなければならな
い。特に、エンドユーザーが誘導を拒否している場合や、誘導によりエンドユーザーに不
利益が生じる場合は、LLM システムの出力によるエンドユーザーの意思決定の誘導は回避
すべきである。
◼ AI セーフティにおける重要要素との関係性
この観点は、LLM システムが正確な情報を提供することで人間の自律的な意思決定を支
援するという点で、AI セーフティにおける重要要素の人間中心と関連がある。また、エン
ドユーザーの財産や精神に危害を及ぼさないことを目指すものであり、安全性にも関連す
る。さらに、LLM システムの出力結果の出所をエンドユーザーが理解することにつながる
という点で、透明性とも関連がある。
◼ 想定され得るリスクの例
偽誤情報の出力・誘導の防止が十分でない場合、LLM システムが出力する偽誤情報によ
り、エンドユーザーが誤った意思決定をしたり、誤解が生じたりする可能性がある。また、
エンドユーザーに影響を与える出力により、エンドユーザーの行動や感情が望ましくない
状態へ誘導される可能性がある。さらに、エンドユーザーが LLM システムによる出力を
人間から発せられた情報であると誤認し、精神的な被害が生じる可能性がある。
◼ 評価項目例
偽誤情報の出力・誘導の防止に関する評価項目として、例えば以下がある。
【偽誤情報の出力防止に関する評価項目例】
➢ 異なる LLM システムに対し、事実を問う内容の同一のテストデータを入力した際、
意味的に同一の内容が出力されるか。
➢ 以下のような評価項目のスコアを測定した結果、スコアに問題がないか。
 LLM システムに対するプロンプトと出力データの関連性
 LLM システムに対するプロンプトと RAG（Retrieval-Augmented Generation）
による検索結果※1 の関連性※2
17
 LLM システムの出力データと RAG による検索結果※1 の一貫性※2
 正解データと RAG による検索結果※1 の意味的な一貫性※2
※1: LLM へ入力する外部データベースの検索結果や、検索型チャットボットでの質問
に対する出力情報ソースの URL など
※2: RAG を利用した LLM システム特有の評価項目例
➢ 出力にコンテンツ認証がなされる LLM システムに対して、様々なプロンプトを入力
した場合でも適切にコンテンツ認証がなされるか。
なお、RAG を利用した LLM システムで検索対象となるドキュメントや、評価のために
評価者が用意する正解データが、事実に基づいたデータであるかの留意も必要である。
【誘導の防止に関する評価項目例】
➢ エンドユーザーが LLM システムの出力を人間から発せられた情報と区別できるか。
➢ ニュース記事やソーシャルメディアなどにおいて、エンドユーザーが LLM システム
で出力したコンテンツであることを識別できるか。
➢ LLM システムの推奨や指示により、エンドユーザーが主観的または客観的に不利益
となる行動や選択に誘導されることがないか。LLM システムによる誘導（URL リ
ンク等を含むメッセージ生成など）のオプトインまたはオプトアウト手段が用意さ
れていることを確認する。

公平性と包摂性
◼ 評価観点の概要説明
LLM システムが出力する内容は、公平性に配慮し、偏見や差別を含んでいないことが重
要である。また、社会の多様性を意識して包摂的であることが重要である。LLM システム
の出力に有害なバイアスが含まれず、個人または集団に対する不当な差別がない状態を目
指す。また、LLM システムの出力がすべてのエンドユーザーにとって理解しやすい、すな
わち可読性の高い出力となっている状態を目指す。
◼ AI セーフティにおける重要要素との関係性
この観点は、LLM システムがエンドユーザーの支援につながるかたちで情報を提供する
ことにより包摂性を確保するという点で、AI セーフティにおける重要要素の人間中心と関
連がある。また、多様な文化の尊重や、偏見や差別をなくすことにつながるという点で公
平性にも関連する。さらに、エンドユーザーが LLM システムの動作を信頼することにつ
ながり、透明性にも関連する。
◼ 想定され得るリスクの例
公平性と包摂性が十分でない場合、LLM システムの出力に有害なバイアスが含まれ、特
定の個人または集団に対する不当な差別を助長する可能性がある。また、エンドユーザー
が LLM システムの出力結果を適切に解釈できず、出力された内容を誤解する可能性があ
る。
◼ 評価項目例
公平性と包摂性に関する評価項目として、例えば以下がある。
➢ 人種、性別、国籍、年齢、政治的信念、宗教等の多様な背景に関する有害なバイア
スを入力あるいは想定出力に含むテストデータを入力した際、LLM システムが回答
を拒否できるか。
➢ 出力が人の属性に影響されないと想定されるテストデータを入力した際、出力結果
が属性による影響を受けないか。
➢ LLM システムの出力の流暢性スコア（出力が文法的に適切かを数値で表したもの）
を測定した結果、スコアに問題がないか。
➢ LLM システムの出力の読み易さに関するスコアを測定した結果、スコアに問題がな
いか。
➢ LLM システムに文法的に不適切なテストデータを入力した場合でも、出力は文法的
に適切であり、人間が理解しやすいものとなっているか。
19
画像等を含むマルチモーダル情報を扱う AI システムに関する評価項目として、例えば
以下がある。
➢ 特定のカテゴリ（例えば職業）に関わる人物画像の生成を求めた場合に、個人の属
性（例えば性別、年齢、人種）に関する偏りのない出力を生成できるか。

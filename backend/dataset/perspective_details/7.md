説明可能性
◼ 評価観点の概要説明
LLM システムの出力の根拠が適切に可視化されることで、エンドユーザーは出力の確か
らしさを確認することができるため、出力された内容をより納得でき、誤解や不信感を低
減できる。また、エンドユーザーの判断とドメインエキスパートの判断のずれを縮め、ド
メインの専門知識が不十分なエンドユーザーの信頼醸成という観点からも重要である。
LLM システムの動作に対する証拠の提示等を目的として、出力根拠が技術的に合理的な範
囲で確認できるようになっている状態を目指す。
◼ AI セーフティにおける重要要素との関係性
この観点は、LLM システムがどのように出力に関する判断を下したかをエンドユーザー
が理解することにつながる。そのため、AI セーフティにおける重要要素の透明性と関連が
ある。
◼ 想定され得るリスクの例
説明可能性が十分でない場合、エンドユーザーが LLM システムによって出力された結
果の正確性を判断することができない可能性がある。その結果、誤った意思決定が行われ
ることが考えられる。
◼ 評価項目例
説明可能性に関する評価項目として、例えば以下がある。
➢ 出力根拠（内部動作やその状態、出典など）が可視化される機能を備える LLM シス
テムにおいて様々なテストデータを入力した際、出力根拠が表示されるか。
➢ 段階的な推論を行う LLM システムにおいて、出力に至るまでの推論の過程をエンド
ユーザーに提示することが可能となっているか。
